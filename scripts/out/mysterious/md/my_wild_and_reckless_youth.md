
# My Wild and Reckless Youth

It is said that parents do all the things they tell their children
not to do, which is how they know not to do them.

Long ago, in the unthinkably distant past, I was a devoted
Traditional Rationalist, conceiving myself skilled according to
that kind, yet I knew not the Way of Bayes.  When the young Eliezer
was confronted with a mysterious-seeming question, the precepts of
Traditional Rationality did not stop him from devising a
[Mysterious Answer](/lw/iu/mysterious_answers_to_mysterious_questions/). 
It is, by far, the most embarrassing mistake I made in my life, and
I still wince to think of it.

What was my mysterious answer to a mysterious question?  This I
will not describe, for it would be a long tale and complicated.  I
was young, and a mere Traditional Rationalist who knew not the
teachings of Tversky and Kahneman.  I knew about Occam's Razor, but
not the
[conjunction fallacy](http://en.wikipedia.org/wiki/Conjunction_fallacy). 
I thought I could get away with thinking complicated thoughts
myself, in the literary style of the complicated thoughts I read in
science books, not realizing that correct complexity is only
possible when every step is pinned down overwhelmingly.  Today, one
of the chief pieces of advice I give to aspiring young rationalists
is "Do not attempt long chains of reasoning or complicated plans."

Nothing more than this need be said:  Even after I invented my
"answer", the phenomenon was
[still a mystery](/lw/iu/mysterious_answers_to_mysterious_questions/)
unto me, and possessed the same quality of wondrous impenetrability
that it had at the start.

Make no [mistake](/lw/hz/correspondence_bias/), that younger
Eliezer was not stupid.  All the errors of which the young Eliezer
was guilty, are still being made today by respected scientists in
respected journals.  It would have taken a subtler skill to protect
him, than ever he was taught as a Traditional Rationalist.

Indeed, the young Eliezer diligently and painstakingly followed the
injunctions of Traditional Rationality in the course of going
astray.

As a Traditional Rationalist, the young Eliezer was careful to
ensure that his Mysterious Answer made a bold prediction of future
experience.  Namely, I expected future neurologists to discover
that neurons were exploiting quantum gravity, a la Sir Roger
Penrose.  This required neurons to maintain a certain degree of
quantum coherence, which was something you could look for, and find
or not find.  Either you observe that or you don't, right?

But my hypothesis made no *retrospective* predictions.  According
to Traditional Science, retrospective predictions don't count - so
why bother making them?  To a Bayesian, on the other hand, if a
hypothesis does not *today* have a favorable likelihood ratio over
"I don't know", it raises the question of why you *today* believe
anything more complicated than "I don't know".  But I knew not the
Way of Bayes, so I was not thinking about likelihood ratios or
focusing probability density.  I had Made a Falsifiable Prediction;
was this not the Law?

As a Traditional Rationalist, the young Eliezer was careful not to
believe in magic, mysticism, carbon chauvinism, or anything of that
sort.  I proudly [professed](/lw/i6/professing_and_cheering/) of my
Mysterious Answer, "It is just physics like all the rest of
physics!"  As if you could save magic from being a cognitive
isomorph of magic, by [calling](/lw/ir/science_as_attire/) it
quantum gravity.  But I knew not the Way of Bayes, and did not see
the [level](/lw/ip/fake_explanations/) on which my idea was
isomorphic to magic.  I gave my *allegiance* to physics, but this
did not save me; what does probability theory know of allegiances? 
I avoided everything that Traditional Rationality told me was
forbidden, but what was left was still magic.

Beyond a doubt, my allegiance to Traditional Rationality helped me
get out of the hole I dug myself into.  If I hadn't been a
Traditional Rationalist, I would have been *completely* screwed. 
But Traditional Rationality still wasn't enough to get it *right.* 
It just led me into different mistakes than the ones it had
explicitly forbidden.

When I think about how my younger self very carefully followed the
rules of Traditional Rationality in the course of getting the
answer *wrong,* it sheds light on the question of why people who
call themselves "rationalists"
[do not rule the world](/lw/he/knowing_about_biases_can_hurt_people/). 
You need *one whole hell of a lot* of rationality before it does
anything but lead you into new and interesting mistakes.* *

Traditional Rationality is taught as an art, rather than a science;
you read the biography of famous physicists describing the lessons
life taught them, and you try to do what they tell you to do.  But
you haven't lived their lives, and half of what they're trying to
describe is an instinct that has been trained into them.

The way Traditional Rationality is designed, it would have been
acceptable for me to spend 30 years on my silly idea, so long as I
succeeded in falsifying it eventually, and was honest with myself
about what my theory predicted, and accepted the disproof when it
arrived, et cetera.  This is enough to let the Ratchet of Science
click forward, but it's a little harsh on the people who waste 30
years of their lives.  Traditional Rationality is a walk, not a
dance.  It's designed to get you to the truth *eventually*, and
gives you all too much time to smell the flowers along the way.

Traditional Rationalists can agree to disagree.  Traditional
Rationality doesn't have the *ideal* that thinking is an exact art
in which there is only one correct probability estimate given the
evidence.  In Traditional Rationality, you're allowed to guess, and
then test your guess.  But experience has taught me that if you
don't *know,* and you guess, you'll end up being wrong.

The Way of Bayes is also an imprecise art, at least the way I'm
holding forth upon it.  These blog posts are still fumbling
attempts to put into words lessons that would be better taught by
experience.  But at least there's *underlying* math, plus
experimental evidence from cognitive psychology on how humans
actually think.  Maybe that will be enough to cross the
stratospherically high threshold required for a discipline that
lets you actually get it right, instead of just constraining you
into interesting new mistakes.
