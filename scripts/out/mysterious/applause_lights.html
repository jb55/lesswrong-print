<!-- .meta --><!--<div><i><h0>Part 1 of 13 in the sequence &nbsp;<a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i><br/><br/></div>--><div id="entry_t3_jb" class="content clear"><div class="md">
        
  <div><p><strong>Followup to</strong>:&#xA0; <a href="/lw/it/semantic_stopsigns/">Semantic Stopsigns</a>, <a href="/lw/ja/we_dont_really_want_your_participation/">We Don't Really Want Your Participation</a> </p>
<p>At the Singularity Summit 2007, one of the speakers called for democratic, multinational development of AI.&#xA0; So I stepped up to the microphone and asked:</p><blockquote><p>Suppose that a group of democratic republics form a consortium to develop AI, and there's a lot of politicking during the process - some interest groups have unusually large influence, others get shafted - in other words, the result looks just like the products of modern democracies.&#xA0; Alternatively, suppose a group of rebel nerds develops an AI in their basement, and instructs the AI to poll everyone in the world - dropping cellphones to anyone who doesn't have them - and do whatever the majority says.&#xA0; Which of these do you think is more "democratic", and would you feel safe with either?</p></blockquote><p>I wanted to find out whether he believed in the pragmatic adequacy of the democratic political process, or if he believed in the moral rightness of voting.&#xA0; But the speaker replied:</p><blockquote><p>The first scenario sounds like an editorial in Reason magazine, and the second sounds like a Hollywood movie plot.</p></blockquote><p>Confused, I asked:</p><blockquote><p>Then what kind of democratic process <em>did</em> you have in mind?</p></blockquote><a id="more"></a><p>The speaker replied:</p><blockquote><p>Something like the Human Genome Project - that was an internationally sponsored research project.</p></blockquote><p>I asked:</p><blockquote><p>How would different interest groups resolve their conflicts in a structure like the Human Genome Project?</p></blockquote><p>And the speaker said:</p><blockquote><p>I don't know.</p></blockquote><p>This exchange puts me in mind of a <a href="http://www.time.com/time/magazine/article/0,9171,954853,00.html">quote</a> (<del>which I failed to Google</del> found by Jeff Grey and Miguel) from some dictator or other, who was asked if he had any intentions to move his pet state toward democracy:</p><blockquote><p>We believe we are already within a democratic system.&#xA0; Some factors
are still missing, like the expression of the people's will.</p></blockquote><p>The substance of a democracy is the specific mechanism that resolves policy conflicts.&#xA0; If all groups had the same preferred policies, there would be no need for democracy - we would
automatically cooperate.&#xA0; The resolution process can be a direct
majority vote, or an elected legislature, or even a
voter-sensitive behavior of an AI, but it has to be <em>something.&#xA0; </em>What does it <em>mean</em> to call for a "democratic" solution if you don't have a conflict-resolution mechanism in mind?</p>
<p>I think it means that you have said the word "democracy", so the audience is supposed to cheer.&#xA0; It's not so much a <span style="font-style: italic;">propositional</span><em>&#xA0;</em>statement, as the equivalent of the "Applause" light that tells a studio audience when to clap.</p>
<p>This case is remarkable only in that I mistook the applause light for a policy suggestion, with subsequent embarrassment for all.&#xA0; Most applause lights are much more blatant, and can be detected by a simple reversal test.&#xA0; For example, suppose someone says:</p><blockquote><p>We need to balance the risks and opportunities of AI.</p></blockquote><p>If you reverse this statement, you get:</p><blockquote><p>We shouldn't balance the risks and opportunities of AI.</p></blockquote><p>Since the reversal sounds <em>ab</em>normal, the unreversed statement is probably normal, implying it does not convey new information.&#xA0; There are plenty of legitimate reasons for uttering a sentence that would be uninformative in isolation.&#xA0; "We need to balance the risks and opportunities of AI" can introduce a discussion topic; it can emphasize the importance of a specific proposal for balancing; it can criticize an unbalanced proposal.&#xA0; Linking to a normal assertion can convey new information to a bounded rationalist - the link itself may not be obvious.&#xA0; But if <em>no</em> specifics follow, the sentence is probably an applause light.</p>
<p>I am tempted to give a talk sometime that consists of <em>nothing but</em> applause lights, and see how long it takes for the audience to start laughing:</p><blockquote><p>I am here to propose to you today that we need to balance the risks and opportunities of advanced Artificial Intelligence.&#xA0; We should avoid the risks and, insofar as it is possible, realize the opportunities.&#xA0; We should not needlessly confront entirely unnecessary dangers.&#xA0; To achieve these goals, we must plan wisely and rationally.&#xA0; We should not act in fear and panic, or give in to technophobia; but neither should we act in blind enthusiasm.&#xA0; We should respect the interests of all parties with a stake in the Singularity.&#xA0; We must try to ensure that the benefits of advanced technologies accrue to as many individuals as possible, rather than being restricted to a few.&#xA0; We must try to avoid, as much as possible, violent conflicts using these technologies; and we must prevent massive destructive capability from falling into the hands of individuals.&#xA0; We should think through these issues before, not after, it is too late to do anything about them...</p></blockquote></div></div></div>