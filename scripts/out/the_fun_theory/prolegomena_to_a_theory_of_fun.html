<!-- .meta --><!--<div><i><h0>Part 1 of 13 in the sequence &nbsp;<a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i><br/><br/></div>--><div id="entry_t3_wv" class="content clear"><div class="md">
        
  <div><p><em>(This post is part of the <a href="/lw/xy/the_fun_theory_sequence/">Fun Theory Sequence</a>.)</em><br><strong>Followup to</strong>:&#xA0; <a href="/lw/sx/inseparably_right_or_joy_in_the_merely_good/">Joy in the Merely Good</a></p>
<p>Raise the topic of cryonics, uploading, or just medically extended lifespan/healthspan, and some bioconservative neo-Luddite is bound to ask, in portentous tones:</p>
<p style="margin-left: 40px;">"But what will people <em>do </em>all day?"</p>
<p>They don't try to <a href="http://www.singinst.org/blog/2007/10/14/the-meaning-that-immortality-gives-to-life/">actually answer the question</a>.&#xA0; That is not a bioethicist's role, in the scheme of things.&#xA0; They're just there to collect credit for the <a href="/lw/k5/cached_thoughts/">Deep Wisdom</a> of asking the question.&#xA0; It's enough to <em>imply </em>that the question is unanswerable, and therefore, we should all drop dead.</p>
<p>That <a href="/lw/lw/reversed_stupidity_is_not_intelligence/">doesn't mean</a> it's a <em>bad </em>question.</p>
<p>It's not an <em>easy </em>question to answer, either.&#xA0; The primary experimental result in hedonic psychology - the study of happiness - is that people don't <em>know </em>what makes them happy.</p>
<p>And there are many exciting results in this new field, which go a long way toward explaining the emptiness of classical Utopias.&#xA0; But it's worth remembering that<em> human</em> hedonic psychology is not enough for us to consider, if we're asking whether a million-year lifespan could be worth living.</p>
<p>Fun Theory, then, is the field of knowledge that would deal in questions like:</p>
<ul>
<li>"How much fun is there in the universe?"</li>
<li>"Will we ever run out of fun?"</li>
<li>"Are we having fun yet?"</li>
<li>"Could we be having more fun?"</li>
</ul>
<p><a id="more"></a></p>
<p>One major set of experimental results in hedonic psychology has to do with <em>overestimating the impact</em> of life events on happiness.&#xA0; Six months after the event, lottery winners aren't as happy as they expected to be, and quadriplegics aren't as sad.&#xA0; A parent who loses a child isn't as sad as they think they'll be, a few years later.&#xA0; If you look at one moment snapshotted out of their lives a few years later, that moment isn't likely to be about the lost child.&#xA0; Maybe they're playing with one of their surviving children on a swing.&#xA0; Maybe they're just listening to a nice song on the radio.</p>
<p>When people are asked to imagine how happy or sad an event will make them, they anchor on <em>the moment of first receiving the news,</em> rather than realistically imagining the process of daily life years later.</p>
<p>Consider what the Christians made of their Heaven, meant to be literally <em>eternal.</em>&#xA0; Endless rest, the glorious presence of God, and occasionally - in the <a href="/lw/wu/visualizing_eutopia/">more clueless sort of sermon</a> - golden streets and diamond buildings.&#xA0; Is this eudaimonia?&#xA0; It doesn't even seem very <em>hedonic</em>.</p>
<p>As someone who said his share of prayers back in his Orthodox Jewish childhood upbringing, I can personally testify that praising God is an enormously boring activity, even if you're still young enough to truly believe in God.&#xA0; The part about praising God is there as an <a href="/lw/jb/applause_lights/">applause light</a> that no one is allowed to contradict: it's something theists <a href="/lw/i4/belief_in_belief/">believe they <em>should</em> enjoy</a>, even though, if you ran them through an fMRI machine, you probably wouldn't find their pleasure centers lighting up much.</p>
<p>Ideology is one major wellspring of flawed Utopias, containing things that the imaginer believes <em>should </em>be enjoyed, rather than things that would actually be enjoyable.</p>
<p>And eternal <em>rest?</em>&#xA0; What could possibly be more boring than eternal <em>rest?</em></p>
<p>But to an exhausted, poverty-stricken medieval peasant, the Christian Heaven sounds like <em>good news in the moment of being first informed:</em>&#xA0; You can lay down the plow and rest!&#xA0; Forever!&#xA0; Never to work again!</p>
<p>It'd get boring after... what, a week?&#xA0; A day?&#xA0; An hour?<br><span style="font-style: italic;"> </span></p>
<p>Heaven is not configured as a nice place to <em>live.</em>&#xA0; It is rather memetically optimized to be a nice place for an exhausted peasant to <em>imagine.</em>&#xA0; It's not like some Christians <em>actually </em>got a chance to live in various Heavens, and voted on how well they liked it after a year, and then they kept the best one.&#xA0; The Paradise that survived was the one that was <em>retold,</em> not lived.</p>
<p>Timothy Feriss observed, "<em>Living</em> like a millionaire requires <em>doing</em> interesting things and not just owning enviable things."&#xA0; <a href="/lw/wu/visualizing_eutopia/">Golden streets and diamond walls</a> would fade swiftly into the background, once <em>obtained </em>- but so long as you <a href="/lw/oz/scarcity/">don't actually <em>have</em> gold</a>, it stays desirable.</p>
<p>And there's two lessons required to get past such failures; and these lessons are in some sense opposite to one another.</p>
<p>The first lesson is that humans are terrible judges of what will <em>actually </em>make them happy, in the real world and the living moments.&#xA0; Daniel Gilbert's <em>Stumbling on Happiness</em> is the most famous popular introduction to the research.</p>
<p>We need to be ready to correct for such biases - the world that is fun to <em>live in</em>, may not be the world that sounds good when spoken into our ears.</p>
<p>And the second lesson is that there's <em>nothing</em> in the universe out of which to construct Fun Theory, except that which we want for ourselves or prefer to become.</p>
<p>If, <em>in fact</em>, you <em>don't</em> like praying, then there's no higher God than yourself to tell you that you <em>should</em> enjoy it.&#xA0; We sometimes do things we don't like, but that's still our own choice.&#xA0; There's no <em>outside</em> force to scold us for making the wrong decision.</p>
<p>This is something for transhumanists to keep in mind - not because we're tempted to pray, of course, but because there are so many other logical-sounding solutions we wouldn't really <em>want.</em></p>
<p>The transhumanist philosopher <a href="http://en.wikipedia.org/wiki/David_Pearce_%28philosopher%29">David Pearce</a> is an advocate of what he calls the <a href="http://www.hedweb.com/">Hedonistic Imperative</a>:&#xA0; The eudaimonic life is the one that is as pleasurable as possible.&#xA0; So even happiness attained through drugs is good?&#xA0; Yes, in fact:&#xA0; Pearce's motto is "Better Living Through Chemistry".</p>
<p>Or similarly:&#xA0; When giving a small informal talk once on the Stanford campus, I raised the topic of Fun Theory in the post-talk mingling.&#xA0; And someone there said that his ultimate objective was to experience delta pleasure.&#xA0; That's "delta" as in the Dirac delta - roughly, an infinitely high spike (that happens to be integrable).&#xA0; "Why?" I asked.&#xA0; He said, "Because that means I win."</p>
<p>(I replied, "How about if you get two times delta pleasure?&#xA0; Do you win twice as hard?")</p>
<p>In the transhumanist lexicon, "orgasmium" refers to simplified brains that are just pleasure centers experiencing huge amounts of stimulation - a happiness counter containing a large number, plus whatever the minimum surrounding framework to <em>experience</em> it.&#xA0; You can imagine a whole galaxy tiled with orgasmium.&#xA0; Would this be a good thing?</p>
<p>And the vertigo-inducing thought is this - if you would <em>prefer</em> not to become orgasmium, then why <em>should</em> you?</p>
<p>Mind you, there are many reasons why something that sounds unpreferred at first glance, might be worth a closer look.&#xA0; That was the <em>first</em> lesson.&#xA0; Many Christians <em>think </em>they want to go to Heaven.</p>
<p>But when it comes to the question, "Don't I <em>have</em> to want to be as happy as possible?" then the answer is simply "No.&#xA0; If you don't prefer it, why go there?"</p>
<p>There's nothing <em>except </em>such preferences out of which to construct Fun Theory - a second look is still a look, and must still be constructed out of preferences at some level.</p>
<p>In the era of my foolish youth, when <a href="/lw/ty/my_childhood_death_spiral/">I went into an affective death spiral around intelligence</a>, I thought that the <a href="/lw/sx/inseparably_right_or_joy_in_the_merely_good/">mysterious "right" thing</a> that <a href="/lw/u2/the_sheer_folly_of_callow_youth/">any superintelligence would inevitably do</a>, would be to upgrade every nearby mind to superintelligence as fast as possible.&#xA0; Intelligence was good; therefore, more intelligence was better.</p>
<p>Somewhat later I imagined the scenario of <em>unlimited</em> computing power, so that no matter how smart you got, you were still just as far from infinity as ever.&#xA0; That got me thinking about a journey rather than a destination, and <em>allowed </em>me to think "What <em>rate </em>of intelligence increase would be fun?"</p>
<p>But the real break came when I <a href="/lw/sm/the_meaning_of_right/">naturalized my understanding of morality</a>, and value stopped being a mysterious attribute of unknown origins.</p>
<p>Then if there was no outside light in the sky to order me to do things -</p>
<p>The thought occurred to me that I didn't actually <em>want</em> to bloat up immediately into a superintelligence, <em>or</em> have my world transformed instantaneously and completely into something incomprehensible.&#xA0; I'd prefer to have it happen gradually, with time to stop and smell the flowers along the way.</p>
<p>It felt like a very guilty thought, but -</p>
<p>But there was nothing <em>higher </em>to <em>override </em>this preference.</p>
<p>In which case, if the Friendly AI project succeeded, there would be a day after the Singularity to wake up to, and myself to wake up to it.</p>
<p>You may not see why this would be a vertigo-inducing concept.&#xA0; Pretend you're Eliezer<sub>2003</sub> who has spent the last seven years talking about how it's forbidden to try to look beyond the Singularity - because the AI is smarter than you, and if you knew what it would do, you would have to be that smart yourself -</p>
<p>- but what if you don't <em>want</em> the world to be made suddenly incomprehensible?&#xA0; Then there might be something to understand, that next morning, <em>because</em> you don't <em>actually want</em> to wake up in an incomprehensible world, any more than you <em>actually want</em> to suddenly be a superintelligence, or turn into orgasmium.</p>
<p>I can only analogize the experience to a theist who's suddenly told that they <em>can</em> know the mind of God, and it turns out to be only twenty lines of Python.</p>
<p>You may find it hard to sympathize.&#xA0; Well, Eliezer<sub>1996</sub>, who originally made the mistake, was <a href="/lw/u1/a_prodigy_of_refutation/">smart but methodologically inept</a>, as I've mentioned a few times.</p>
<p>Still, expect to see some outraged comments on this very blog post, from commenters who think that it's <em>selfish and immoral</em>, and above all a <em>failure of imagination,</em> to talk about human-level minds still running around the day after the Singularity.</p>
<p>That's the frame of mind I used to occupy - that the things I wanted were selfish, and that I shouldn't think about them too much, or at all, because I would need to sacrifice them for something higher.</p>
<p>People who talk about an existential pit of meaninglessness in a universe devoid of meaning - I'm pretty sure they don't understand morality in naturalistic terms.&#xA0; There <em>is</em> vertigo involved, but it's <em>not</em> the vertigo of meaninglessness<em>.</em></p>
<p>More like a theist who is <a href="/lw/sb/could_anything_be_right/">frightened</a> that someday God will <a href="http://www.thevillageatheist.co.uk/genocide.html">order him to murder children</a>, and then he realizes that there <em>is</em> no God and his fear of being ordered to murder children <em><a href="/lw/ky/fake_morality/">was morality</a></em>.&#xA0; It's a strange relief, mixed with the realization that you've been very silly, as the last remnant of outrage at your own selfishness fades away.</p>
<p>So the first step toward Fun Theory is that, so far as I can tell, it looks basically <em>okay </em>to make our future light cone - all the galaxies that we can get our hands on - into a place that is <em>fun</em> rather than <em>not fun.</em></p>
<p>We don't need to transform the universe into something we feel <em>dutifully obligated</em> to create, but isn't really much fun - in the same way that a Christian would feel dutifully obliged to enjoy heaven - or that some strange folk think that creating orgasmium is, logically, the rightest thing to do.</p>
<p>Fun is okay.&#xA0; It's allowed.&#xA0; It doesn't get any better than fun.</p>
<p>And then we can turn our attention to the question of what <em>is</em> fun, and how to have it.</p></div></div></div>