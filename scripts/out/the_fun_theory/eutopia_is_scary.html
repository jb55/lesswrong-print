<!-- .meta --><!--<div><i><h0>Part 1 of 13 in the sequence &nbsp;<a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i><br/><br/></div>--><div id="entry_t3_xl" class="content clear"><div class="md">
        
  <div><p><em>(This post is part of the <a href="/lw/xy/the_fun_theory_sequence/">Fun Theory Sequence</a>.)</em><br> <strong>Followup to</strong>:&#xA0; <a href="/lw/j6/why_is_the_future_so_absurd/">Why is the Future So Absurd?</a></p>
<p style="margin-left: 40px;">"The big thing to remember about far-future cyberpunk is that it will be truly <em>ultra</em>-tech.&#xA0; The mind and body changes available to a 23rd-century Solid Citizen would probably amaze, disgust and <em>frighten</em> that 2050 netrunner!"<br>&#xA0;&#xA0;&#xA0; &#xA0;&#xA0;&#xA0; -- <em>GURPS Cyberpunk</em></p>
<p>Pick up someone from the 18th century - a <em>smart</em> someone.&#xA0; Ben Franklin, say.&#xA0; Drop them into the early 21st century.</p>
<p>We, in our time, think our life has improved in the last two or three hundred years.&#xA0; Ben Franklin is probably smart and forward-looking enough to <em>agree</em> that life has improved.&#xA0; But if you don't think Ben Franklin would be amazed, disgusted, and <em>frightened</em>, then I think <a href="/lw/j6/why_is_the_future_so_absurd/">you far overestimate the "normality" of your own time</a>.&#xA0; You can think of reasons why Ben should find our world compatible, but Ben himself might not do the same.</p>
<p><span id="comment-81958465-content">Movies that were made in say the 40s or 50s, seem much more alien - to me - than modern movies allegedly set hundreds of years in the future, or in different universes.&#xA0; Watch a movie from 1950 and you may see a man slapping a woman.&#xA0; Doesn't happen a lot in <em>Lord of the Rings</em>, does it?</span>&#xA0; Drop back to the 16th century and one popular entertainment was setting a cat on fire.&#xA0; Ever see <em>that</em> in any moving picture, no matter how "lowbrow"?</p>
<p>("But," you say, "that's showing how discomforting the Past's culture was, not how scary the Future is."&#xA0; Of which I <a href="/lw/j6/why_is_the_future_so_absurd/">wrote</a>,&#xA0;"When we look over history, we see changes away from <em>absurd</em> conditions such as everyone being a peasant farmer and women not having the vote, toward <em>normal</em> conditions like a majority middle class and equal rights...")</p>
<p><em>Something</em> about the Future will shock we 21st-century folk, if we were dropped in without slow adaptation.&#xA0; This is not because the Future is cold and gloomy - I am speaking of a positive, successful Future; the negative outcomes are probably just blank.&#xA0; Nor am I speaking of the idea that every Utopia has some dark hidden flaw.&#xA0; I am saying that the Future would discomfort us <em>because</em> it is better.</p>
<p><a id="more"></a></p>
<p>This is another piece of the puzzle for why <a href="http://www.orwell.ru/library/articles/socialists/english/e_fun">no author seems to have ever succeeded in constructing a Utopia worth-a-damn</a>.&#xA0; When they are out to depict how marvelous and wonderful the world could be, if only we would all be Marxists or Randians or let philosophers be kings... they try to depict the resulting outcome as <em>comforting</em> and <em>safe.</em></p>
<p>Again, George Orwell from "<a href="http://www.orwell.ru/library/articles/socialists/english/e_fun">Why Socialists Don't Believe In Fun</a>":</p>
<blockquote>
<p>&#xA0;&#xA0;&#xA0; "<span id="comment-144622762-content">In the last part, in contrast with disgusting Yahoos, we are shown the noble Houyhnhnms, intelligent horses who are free from human failings.&#xA0; Now these horses, for all their high character and unfailing common sense, are remarkably dreary creatures.&#xA0; Like the inhabitants of various other Utopias, they are chiefly concerned with avoiding fuss.&#xA0; They live uneventful, subdued, 'reasonable' lives, free not only from quarrels, disorder or insecurity of any kind, but also from 'passion', including physical love.&#xA0; They choose their mates on eugenic principles, avoid excesses of affection, and appear somewhat glad to die when their time comes."</span></p>
</blockquote>
<p>One might consider, in particular contrast, Timothy Ferris's observation:</p>
<p style="margin-left: 40px;">&#xA0;&#xA0;&#xA0; "What is the opposite of happiness?&#xA0; Sadness?&#xA0; No.&#xA0; Just as love and hate are two sides of the same coin, so are happiness and sadness.&#xA0; Crying out of happiness is a perfect illustration of this.&#xA0; The opposite of love is indifference, and the opposite of happiness is - here's the clincher - boredom...<br> &#xA0;&#xA0;&#xA0; The question you should be asking isn't 'What do I want?' or 'What are my goals?' but 'What would excite me?'<br> &#xA0;&#xA0;&#xA0; Remember - boredom is the enemy, not some abstract 'failure.'"</p>
<p>Utopia is reassuring, unsurprising, and dull.</p>
<p>Eutopia is scary.</p>
<p>I'm not talking here about <a href="/lw/uu/why_does_power_corrupt/">evil means to a good end</a>, I'm talking about the good outcomes <em>themselves</em>.&#xA0; That is the proper relation of the Future to the Past when things turn out <em>well</em>, as we would know very well from history <a href="/lw/iz/failing_to_learn_from_history/">if we'd actually lived it</a>, rather than looking back with benefit of hindsight.</p>
<p>Now... I don't think you can actually <em>build the Future</em> on the basis of asking how to scare yourself.&#xA0; The vast majority of possible changes are in the direction of higher entropy; only a very few discomforts stem from things getting <em>better</em>.</p>
<p>"I shock you therefore I'm right" is one of the most <em>annoying</em> of all non-sequiturs, and we certainly don't want to go <em>there.</em></p>
<p>But on a purely <em>literary</em> level... and bearing in mind that <a href="/lw/k9/the_logical_fallacy_of_generalization_from/">fiction is not reality</a>, and <a href="/lw/xi/serious_stories/">fiction is not optimized the way we try to optimize reality</a>...</p>
<p>I try to write fiction, now and then.&#xA0; More rarely, I finish a story.&#xA0; Even more rarely, I let someone else look at it.</p>
<p>Once I finally got to the point of thinking that <a href="/lw/xi/serious_stories/">maybe you <em>should</em> be able to write a story set in Eutopia</a>, I tried doing it.&#xA0;</p>
<p>But I had something like an instinctive revulsion at the indulgence of trying to build a world that fit <em>me,</em> but probably wouldn't fit others so nicely.</p>
<p>So - without giving the world a seamy underside, or putting <a href="http://tvtropes.org/pmwiki/pmwiki.php/Main/KnightTemplar">Knight Templars</a> in charge, or anything so obvious as that - without deliberately trying to make the world<em> flawed </em>-</p>
<p>I was trying to invent, even if I had to do it myself, a better world where I would be <em>out of place.</em>&#xA0; Just like Ben Franklin would be out of place in the modern world.</p>
<p>Definitely <em>not</em> someplace that a transhumanist/science-advocate/libertarian (like myself) would go, and be smugly satisfied at how well all their ideas had worked.&#xA0; Down that path lay the Dark Side - certainly in a purely literary sense.</p>
<p>And you couldn't avert that just by having the Future go wrong in all the stupid obvious ways that transhumanists, or libertarians, or public advocates of science had already warned against.&#xA0; Then you just had a dystopia, and it might make a good SF story but it had already been done.</p>
<p>But I had my world's foundation, an absurd notion inspired by a corny pun; a vision of what you see when you wake up from cryonic suspension, that I couldn't have gotten away with posting to any transhumanist mailing list even as a joke.</p>
<p>And then, whenever I could think of an arguably-good idea that <em>offended my sensibilities</em>, I added it in.&#xA0; The goal being to - without ever deliberately making the Future <em>worse </em>- make it a place where I would be as shocked as possible to see that <em>that</em> was how things had turned out.</p>
<p><a href="/lw/p0/to_spread_science_keep_it_secret/">Getting rid of textbooks</a>, for example - postulating that talking about science in public is socially unacceptable, for the same reason that you don't tell someone aiming to see a movie whether the hero dies at the end.&#xA0; A world that had rejected my beloved concept of <a href="/lw/in/scientific_evidence_legal_evidence_rational/">science as the public knowledge of humankind</a>.</p>
<p>Then I added up all the discomforting ideas together...</p>
<p>...and at least in my imagination, it worked better than anything I'd ever dared to visualize as a <em>serious </em>proposal.</p>
<p>My serious proposals had been optimized to look sober and safe and sane; everything <a href="/lw/x3/devils_offers/">voluntary</a>, with <a href="/lw/wz/living_by_your_own_strength/">clearly lighted</a> <a href="/lw/x2/harmful_options/">exit signs</a>, and all sorts of <a href="/lw/xg/emotional_involvement/">volume controls</a> to prevent anything from getting too <em>loud</em> and waking up the neighbors.&#xA0; Nothing too <a href="/lw/j6/why_is_the_future_so_absurd/">absurd</a>.&#xA0; Proposals that wouldn't scare the nervous, containing as little as possible that would cause anyone to make a fuss.</p>
<p>This world was ridiculous, and it was going to wake up the neighbors.</p>
<p>It was also seductive to the point that I had to exert a serious effort to prevent my soul from getting sucked out.&#xA0; (I suspect that's a general problem; that it's a good idea <em>emotionally </em>(not just <em>epistemically</em>) to <em>not </em>visualize your better Future in too much detail.&#xA0; You're better off comparing yourself to the Past.&#xA0; I may write a separate post on this.)</p>
<p>And so I found myself being pulled in the direction of this world in which I was supposed to be "out of place".&#xA0; I started thinking that, well, maybe it really <em>would</em> be a good idea to get rid of all the textbooks, all they do is take the fun out of science.&#xA0; I started thinking that maybe personal competition <em>was </em>a legitimate motivator (previously, I would have called it a zero-sum game and been morally aghast).&#xA0; I began to worry that peace, democracy, market economies, and con - but I'd better not finish that sentence.&#xA0; I started to wonder if the old vision that was so <em>reassuring,</em> so <em>safe,</em> was <a href="/lw/wv/prolegomena_to_a_theory_of_fun/">optimized to be good news</a> to a modern human living in constant danger of permanent death or damage, and less optimized for the everyday existence of someone less frightened.</p>
<p>This is what happens when I try to invent a world that fails to confirm my sensibilities?&#xA0; It makes me wonder what would happen if someone else tried the same exercise.</p>
<p>Unfortunately, I can't seem to visualize any new world that represents the same shock to me as the last one did.&#xA0; Either the trick only works once, or you have to wait longer between attempts, or I'm too old now.</p>
<p>But I hope that so long as the world offends the <em>original</em> you, it gets to keep its literary integrity even if you start to find it less shocking.</p>
<p>I haven't yet published any story that gives more than a glimpse of this setting.&#xA0; I'm still debating with myself whether I dare.&#xA0; I don't know whether the suck-out-your-soul effect would threaten anyone but myself as author - I haven't seen it happening with Banks's Culture or Wright's Golden Oecumene, so I suspect it's more of a trap when a world fits a single person too well.&#xA0; But I got enough flak when I presented <a href="/lw/p0/to_spread_science_keep_it_secret/">the case for getting rid of textbooks</a>.</p>
<p>Still - I have seen the possibilities, now.&#xA0; So long as no one dies permanently, I am leaning in favor of a loud and scary Future<span style="font-style: italic;">.</span><em></em></p></div></div></div>