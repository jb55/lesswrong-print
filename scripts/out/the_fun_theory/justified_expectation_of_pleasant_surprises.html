<!-- .meta --><!--<div><i><h0>Part 1 of 13 in the sequence &nbsp;<a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i><br/><br/></div>--><div id="entry_t3_xo" class="content clear"><div class="md">
        
  <div><p><em>(This post is part of the <a href="../lw/xy/the_fun_theory_sequence/">Fun Theory Sequence</a>.)</em><a href="/lw/xl/eutopia_is_scary/"></a></p>
<p>I recently tried playing a computer game that made a major fun-theoretic error.&#xA0; (At least I strongly suspect it's an error, though they are game designers and I am not.)</p>
<p>The game showed me - right from the start of play - what abilities I could purchase as I increased in level.&#xA0; Worse, there were <a href="/lw/x2/harmful_options/">many different choices</a>; still worse, you had to pay a cost in fungible points to acquire them, making you feel like you were losing a resource...&#xA0; But today, I'd just like to focus on the problem of telling me, <em>right at the start of the game,</em> about all the nice things that might happen to me later.</p>
<p>I can't think of a good experimental result that backs this up; but I'd expect that a pleasant <em>surprise</em> would have a greater hedonic impact, than being told about the same gift in advance.&#xA0; Sure, the moment you were first <em>told </em>about the gift would be <em>good news</em>, a moment of pleasure in the moment of being told.&#xA0; But you wouldn't have the gift in hand at that moment, which limits the pleasure.&#xA0; And then you have to wait.&#xA0; And then when you finally get the gift - it's pleasant to go from not having it to having it, <em>if</em> you didn't wait too long; but a surprise would have a larger momentary impact, I would think.</p>
<p>This particular game had a status screen that showed <em>all</em> my future class abilities <em>at the start of the game</em> - inactive and dark but with full information still displayed.&#xA0; From a hedonic standpoint this seems like <em>miserable </em>fun theory.&#xA0; All the "good news" is lumped into a gigantic package; the items of news would have much greater impact if encountered separately.&#xA0; And then I have to wait a long time to actually acquire the abilities, so I get an extended period of comparing my current weak game-self to all the wonderful abilities I <em>could</em> have but don't.</p>
<p>Imagine living in two possible worlds.&#xA0; Both worlds are otherwise rich in <a href="/lw/ww/high_challenge/">challenge</a>, <a href="/lw/wx/complex_novelty/">novelty</a>, and other aspects of Fun.&#xA0; In both worlds, you get smarter with age and <a href="/lw/wz/living_by_your_own_strength/">acquire more abilities over time</a>, so that your life is <a href="/lw/xk/continuous_improvement/">always getting better</a>.</p>
<p>But in <em>one </em>world, the abilities that come with seniority are openly discussed, hence widely known; you know what you have to look forward to.</p>
<p>In the <em>other </em>world, anyone older than you will <em>refuse to talk</em> about certain aspects of growing up; you'll just have to wait and find out.</p>
<p><a id="more"></a></p>
<p>I ask you to contemplate - not just which world you might prefer to live in - but how <em>much</em> you might want to live in the second world, rather than the first.&#xA0; I would even say that the second world seems more <em>alive;</em> when I imagine living there, my imagined <em>will to live</em> feels stronger.&#xA0; I've got to stay alive to find out what happens next, right?</p>
<p>The idea that <em>hope</em> is important to a happy life, is hardly original with me - though I think it might not be emphasized quite <em>enough</em>, on the lists of things people are told they need.</p>
<p>I <a href="/lw/hl/lotteries_a_waste_of_hope/">don't agree with buying lottery tickets</a>, but I do think I understand why people do it.&#xA0; I remember the times in my life when I had more or less belief that things would improve - that they were heading up in the near-term or mid-term, close enough to anticipate.&#xA0; I'm having trouble describing how much of a difference it makes.&#xA0; Maybe I don't <em>need</em> to describe that difference, unless some of my readers have never had any light at the end of their tunnels, or some of my readers have never looked forward and seen darkness.</p>
<p>If <a href="/lw/sc/existential_angst_factory/">existential angst</a> comes from having at least one deep problem in your life that you aren't thinking about explicitly, so that the pain which comes from it seems like a natural permanent feature - then the very first question I'd ask, to identify a possible source of that problem, would be, "Do you expect your life to improve in the near or mid-term future?"</p>
<p>Sometimes I meet people who've been run over by life, in much the same way as being run over by a truck.&#xA0; Grand catastrophe isn't necessary to destroy a will to live.&#xA0; The extended absence of hope leaves the same sort of wreckage.</p>
<p>People need hope.&#xA0; I'm not the first to say it.</p>
<p>But I think that the importance of <em>vague hope</em> is underemphasized.</p>
<p>"Vague" is usually not a compliment among rationalists.&#xA0; Hear "vague hopes" and you immediately think of, say, an alternative medicine herbal profusion whose touted benefits are so conveniently unobservable (not to mention experimentally unverified) that people will buy it for anything and then refuse to admit it didn't work.&#xA0; You think of poorly worked-out plans with missing steps, or supernatural prophecies made carefully unfalsifiable, or fantasies of unearned riches, or...</p>
<p>But you know, generally speaking, our beliefs about the future <em>should</em> be vaguer than our beliefs about the past.&#xA0; We just know less about tomorrow than we do about yesterday.</p>
<p>There are plenty of <em>bad</em> reasons to be vague, all sorts of <em>suspicious </em>reasons to offer nonspecific predictions, but <a href="/lw/lw/reversed_stupidity_is_not_intelligence/">reversed stupidity is not intelligence</a>:&#xA0; When you've eliminated all the ulterior motives for vagueness, your beliefs about the future should <em>still </em>be vague.</p>
<p>We don't know much about the future; let's hope <em>that </em>doesn't change for <a href="/lw/xg/emotional_involvement/">as long as human emotions stay what they are</a>.&#xA0; Of all the poisoned gifts a big mind could give a small one, <a href="/lw/x3/devils_offers/">a walkthrough for the game</a> has to be near the top of the list.</p>
<p>What we need to maintain our interest in life, is a <em>justified expectation of pleasant surprises.</em>&#xA0; (And yes, you can <a href="/lw/v7/expected_creative_surprises/">expect a surprise</a> if you're not logically omniscient.)&#xA0; This excludes the herbal profusions, the poorly worked-out plans, and the <a href="/lw/tv/excluding_the_supernatural/">supernatural</a>.&#xA0; The best reason for this justified expectation is <em>experience</em>, that is, being pleasantly surprised on a frequent yet irregular basis.&#xA0; (If this isn't happening to you, please file a bug report with the appropriate authorities.)</p>
<p><em>Vague justifications</em> for believing in a pleasant <em>specific outcome</em> would be the opposite.</p>
<p>There's also other dangers of having pleasant hopes that are <em>too specific</em> - even if <em>justified</em>, though more often they aren't - and I plan to talk about that in the next post.</p></div></div></div>