<!-- .meta --><!--<div><i><h0>Part 1 of 13 in the sequence &nbsp;<a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i><br/><br/></div>--><div id="entry_t3_qf" class="content clear"><div class="md">
        
  <div><p><strong>Followup to</strong>:&#xA0; <a href="/lw/qb/science_doesnt_trust_your_rationality/">Science Doesn't Trust Your Rationality</a>, <a href="/lw/qe/do_scientists_already_know_this_stuff/">Do Scientists Already Know This Stuff?</a></p>
<p>I don't ask my friends about their childhoods - I lack social
curiosity - and so I don't know how much of a trend this really is:</p>
<p>Of
the people I know who are reaching upward as rationalists, who
volunteer information about their childhoods, there is a surprising
tendency to hear things like:&#xA0; "My family joined a cult and I had to
break out," or "One of my parents was clinically insane and I had to
learn to filter out reality from their madness."</p>
<p>My own experience
with growing up in an Orthodox Jewish family seems tame by
comparison... but it accomplished the same outcome:&#xA0; It broke my core
emotional trust in the sanity of the people around me.</p>
<p dragover="true">Until this core emotional trust is broken, you don't
start growing as a rationalist.&#xA0; I have trouble putting into words why
this is so.&#xA0; Maybe any <em>unusual</em> skills you acquire - anything that
makes you <em>unusually </em>rational - requires you to zig when
other people zag.&#xA0; Maybe that's just too scary, if the world still
seems like a sane place unto you.<br>
</p>
<p dragover="true">Or maybe you don't bother putting in the hard work to be extra bonus sane, if normality doesn't scare the hell out of you.</p>
<a id="more"></a><p dragover="true">I know that many aspiring rationalists seem to run
into roadblocks around things like cryonics or many-worlds.&#xA0; Not that
they don't see the logic; they see the logic and wonder, "Can this really be true,
when it seems so obvious now, and yet none of the people around me believe it?"</p>
<p dragover="true">Yes.&#xA0; Welcome to the Earth where ethanol is made from corn and environmentalists oppose nuclear power.&#xA0; I'm sorry.</p><blockquote><p dragover="true">(See also:&#xA0; <a href="/lw/md/cultish_countercultishness/">Cultish Countercultishness</a>.&#xA0; If you end up in the frame of mind of <em>nervously seeking reassurance</em>, this is never a good thing - even if it's because you're about to believe something that sounds logical but could cause other people to look at you funny.)</p></blockquote><p dragover="true">People who've had their trust broken in the sanity of the people around
them, seem to be able to evaluate strange ideas on their merits,
without feeling <em>nervous </em>about
their strangeness.&#xA0; The glue that binds them to their current place
has dissolved, and they can walk in some direction, hopefully forward.</p>
<p><a href="/lw/mb/lonely_dissent/">Lonely
dissent</a>,
I called it.&#xA0; True dissent doesn't feel like going to school wearing
black; it feels like going to school wearing a clown suit.</p>
<p>That's what it takes to be the lone voice who says, "If you <em>really</em> think <em>you</em> know who's going to win the election, why aren't you picking up the <a href="/lw/ni/buy_now_or_forever_hold_your_peace/">free money</a>
on the Intrade prediction market?" while all the people around you are
thinking, "It is good to be an individual and form your own opinions,
the shoe commercials told me so."</p>
<p>Maybe in some other world, some alternate Everett branch with a saner human population, things would be different... but in <em>this</em>
world, I've never seen anyone begin to grow as a rationalist until they
make a deep emotional break with the <a href="/lw/m9/aschs_conformity_experiment/">wisdom of their pack</a>.</p>
<p>Maybe in another world, things would be different.&#xA0; And maybe not.&#xA0; I'm not sure that human beings realistically <em>can</em> trust and think at the same time.</p>
<p>Once upon a time, there was something I trusted.</p>
<p>Eliezer<sub>18</sub> trusted Science.</p>
<p>Eliezer<sub>18</sub> dutifully acknowledged that the social process of
science was flawed.&#xA0; Eliezer<sub>18</sub> dutifully acknowledged that academia was slow,
and misallocated resources, and played favorites, and mistreated its precious
heretics.</p>
<p>That's the convenient thing about acknowledging flaws in <em>people</em> who failed to live up to your ideal; you don't have to question the <em>ideal itself</em>.</p>
<p>But who could possibly be foolish enough to question, "The experimental method shall decide which hypothesis wins"?</p>
<p>Part of what fooled Eliezer<sub>18</sub> was a (major!) general problem he had, with an aversion to ideas that <em>resembled</em> things idiots had said.&#xA0; (See:&#xA0; <a href="/lw/lw/reversed_stupidity_is_not_intelligence/">Reversed stupidity is not intelligence</a>.)</p>
<p>Eliezer<sub>18</sub> had seen <em>plenty</em> of people questioning the ideals of Science Itself, and they were <em>all</em>
on the Dark Side.&#xA0; It's not like these people were saying, "Okay,
here's how I think an excessive focus on definitive experiments <a href="/lw/q8/many_worlds_one_best_guess/">misled
physicists</a> on the decoherence interpretation of quantum mechanics, and
here's how you can <a href="/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/">do better</a> using probability theory..."&#xA0; People who
questioned the <em>ideal </em>of Science were invariably trying to sell you
snake oil, or trying to safeguard their favorite form of stupidity from
criticism, or trying to disguise their personal resignation as a Deeply
Wise acceptance of futility.</p>
<p>And Eliezer<sub>18</sub> flinched away from being like these people; so he never questioned the ideal of the experimental method.</p>
<p>This is one reason that in these blog posts I am confronting,
head-on, Science Itself.&#xA0; (Sure, someone may come back later and use
these posts to paint me as a lunatic, but frankly, anyone who wishes to
paint me as a lunatic already has <em>more than enough</em> material to misquote.)&#xA0; The natural assumption that anyone who seriously challenges Science is on the Dark Side, meant that this was one of <em>very few things</em> that Eliezer<sub>18</sub> didn't think about much.&#xA0; Of course those "few things" turned out to contain the evil black box surprises from hell.</p>
<p>If there'd been any other ideal that was a few centuries old, the
young Eliezer would have looked at it and said, "I wonder if this is
really right, and whether there's a way to <a href="/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/">do better</a>."&#xA0; But not the ideal of Science.&#xA0; Science was the <em>master</em> idea, the idea that let you change ideas.&#xA0; You could <em>question</em> it, but you were meant to <a href="/lw/ib/the_proper_use_of_doubt/">question it and then accept it</a>, not actually say, "Wait!&#xA0; This is wrong!"</p>
<p>Thus, when once upon a time I came up with a stupid idea, I thought
I was behaving virtuously if I made sure there was a novel prediction,
and professed that I wished to test my idea experimentally.&#xA0; I thought
I had
done everything I was obliged to do.
</p>
<p>So I thought I was <em>safe </em>- not safe
from any particular external threat, but safe on some deeper level,
like a child who trusts their parent and has obeyed all the parent's
rules.</p>
<p>I'd long since been broken of trust in the sanity of
my family or my teachers at school.&#xA0; And the other children weren't
intelligent enough to compete with the conversations I could have with
books.&#xA0; But I trusted the books, you see.&#xA0; I trusted that if I did what
Richard Feynman told me to do, I would be safe.&#xA0; I never thought
those words aloud, but it was how I felt.</p>
<p>When Eliezer<sub>23</sub> realized exactly <em>how</em> stupid the
stupid theory had been - and that Traditional Rationality had not saved
him from it - and that Science would have been perfectly okay with his
wasting ten years testing the stupid idea, so long as afterward he
admitted it was wrong...

</p>
<p>...well, I'm not going to say it was a huge emotional
convulsion.&#xA0; I don't really go in for that kind of drama.&#xA0; It simply
became obvious that I'd been stupid.</p>
<p>That's the trust I'm trying to break in you.&#xA0; You are not safe.&#xA0; 
Ever.</p>
<p>Not even Science can save you.&#xA0; The ideals of Science were born
centuries ago, in a time when no one knew anything about probability
theory or cognitive biases.&#xA0; Science demands <em>too little</em> of you, it
blesses your good intentions too easily, <a href="/lw/qd/science_isnt_strict_enough/">it is not strict <em>enough</em></a>, it
only makes those injunctions that an <a href="/lw/qe/do_scientists_already_know_this_stuff/">average scientist</a> can follow, it accepts <a href="/lw/q9/the_failures_of_eld_science/">slowness</a> as a fact of life.</p>
<p>So don't think that if you only follow the rules of Science, that makes your reasoning defensible.</p>
<p>There is no known procedure you can follow that makes your reasoning defensible.</p><p>There is no known set of injunctions which you can satisfy, and know that you will not have been a fool.</p>
<p>There is no known morality-of-reasoning that you can do your best to
obey, and know that you are thereby shielded from criticism.</p>
<p>No, not even if you turn to Bayescraft.&#xA0; It's much harder to use and
you'll never be sure that you're doing it right.</p>
<p>The discipline of Bayescraft is younger by far than the discipline
of Science.&#xA0; You will find no textbooks, no elderly mentors, no
histories written of success and failure, no hard-and-fast rules laid
down.&#xA0; You will have to study cognitive biases, and probability theory,
and evolutionary psychology, and social psychology, and other cognitive
sciences, and Artificial Intelligence - and think through for <em>yourself</em> how to apply all this knowledge to the case of correcting yourself, since it isn't yet in the textbooks.



</p>
<p dragover="true">You don't know what your own mind is really doing. 
They find a new cognitive bias every week and you're never sure if
you've corrected for it, or overcorrected.</p>
<p dragover="true">The formal math is impossible to apply.&#xA0; It doesn't
break down as easily as John Q. Unbeliever thinks, but you're never
really sure where the foundations come from.&#xA0; You don't know why the
universe is simple enough to understand, or why <em>any</em> prior works for it.&#xA0; You don't know what your own priors <em>are,</em> let alone if they're any good.</p>
<p>One of the problems with Science is that it's too vague to
really <em>scare </em>you.&#xA0; "Ideas should be tested by experiment."&#xA0; How
can you go wrong with that?</p>
<p dragover="true">On the other hand, if you have
some math of probability theory laid out in front of you, and worse, <em>you know you can't actually use it,</em> then it becomes clear that you are trying to do something <em>difficult,</em> and that you might well be doing it <em>wrong.</em></p>
<p>So you cannot trust.</p>
<p>And all this that I have said, <em>will not be sufficient</em> to break your trust.&#xA0; That won't happen until you get into your first real disaster from <em>following </em>The Rules, not from breaking them.</p>
<p>Eliezer<sub>18</sub> already had the notion that you were <em>allowed </em>to question Science.&#xA0; Why, of course the scientific method was not itself immune to questioning!&#xA0; For are we not all good rationalists?&#xA0; Are we not allowed to question everything?</p>
<p>It was the notion that you could <em>actually in real life</em> follow Science and fail miserably, that Eliezer<sub>18</sub>&#xA0; didn't <em>really, emotionally</em> believe was possible.</p>
<p>Oh, of course he <em>said</em> it was possible.&#xA0; Eliezer<sub>18</sub>&#xA0; dutifully acknowledged the possibility of error, saying, "I could be wrong, but..."</p>
<p>But he didn't think failure could happen in, you know, <em>real life.</em>&#xA0; You were supposed to <em>look</em> for flaws, not <a href="/lw/ib/the_proper_use_of_doubt/">actually find them</a>.</p>
<p>And this emotional difference is a terribly difficult thing to accomplish in words, and I fear there's no way I can really warn you.</p>
<p>Your trust will not break, until you apply all that you have learned here
and from other books, and take it as far as you can go, and find that <em>this too</em>
fails you - that you have still been a fool, and no one warned you
against it - that all the most important parts were left out of the
guidance you received - that some of the most precious ideals you
followed, steered you in the wrong direction -</p>
<p>- and if you still have <a href="/lw/nb/something_to_protect/">something to protect</a>, so that you <em>must </em>keep going, and <em>cannot</em> resign and wisely acknowledge the limitations of rationality -</p>
<p><em>- then</em> you will be ready to start your journey as a
rationalist.&#xA0; To take sole responsibility, to live
without any trustworthy defenses, and to forge a higher Art than the
one you were once taught.</p>
<p>No one begins to truly search for the Way until their parents have failed them, their gods
are dead, and their tools have shattered in their hand.</p>
<hr>
<p><strong>Post Scriptum:</strong>&#xA0; On reviewing a draft of this essay, I discovered a fairly inexcusable flaw in reasoning, which actually affects one of the conclusions drawn.&#xA0; I am <a href="http://www.overcomingbias.com/2008/02/my-favorite-lia.html">leaving it in</a>.&#xA0; Just in case you thought that taking my advice made you safe; or that you were supposed to <em>look </em>for flaws, but not <em>find </em>any.</p>
<p>And of course, if you look <em>too hard</em> for a flaw, and find a flaw that is not a real flaw, and cling to it to reassure yourself of how critical you are, you will only be worse off than before...</p>
<p>It is living with uncertainty - knowing on a gut level that <em>there are flaws</em>, <em>they are serious</em> and <em>you have not found them</em> - that is the difficult thing.</p></div></div></div>