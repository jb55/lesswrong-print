<!-- .meta --><!--<div><i><h0>Part 1 of 13 in the sequence &nbsp;<a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i><br/><br/></div>--><div id="entry_t3_qi" class="content clear"><div class="md">
        
  <div><p><strong>Followup to</strong>:&#xA0; <a href="/lw/qb/science_doesnt_trust_your_rationality/">Science Doesn't Trust Your Rationality</a>, <a href="/lw/jo/einsteins_arrogance/">Einstein's Arrogance</a></p>
<p>I sometimes say that the method of science is to amass such an enormous mountain of evidence that even scientists cannot ignore it; and that this is the distinguishing characteristic of a scientist, a non-scientist will ignore it anyway.</p>
<p>Max Planck was even less optimistic:</p><blockquote><p>"A new scientific truth does not triumph by
convincing its opponents
and making them see the light, but rather because its opponents
eventually die, and a new generation grows up that is familiar with
it."</p></blockquote><p>I am much tickled by this notion, because it implies
that the power of science to distinguish truth from falsehood
ultimately rests on the good taste of grad students.</p>
<p dragover="true">The <em>gradual</em> increase in acceptance of <a href="/lw/q8/many_worlds_one_best_guess/">many-worlds</a> in academic physics, suggests that there are physicists who will only accept a new idea given some <em>combination</em> of epistemic justification, and a
sufficiently large academic pack in whose company they can be
comfortable.&#xA0; As more physicists accept, the pack grows larger, and
hence more people go over their individual thresholds for conversion -
with the epistemic justification remaining essentially the same.</p>
<p>But Science still gets there <em>eventually,</em> and this is sufficient for the ratchet of Science to move forward, and raise up a technological civilization.</p>
<p>Scientists can be moved by groundless prejudices, by undermined intuitions, by raw herd behavior - the panoply of human flaws.&#xA0; Each time a scientist shifts belief for epistemically unjustifiable reasons, it requires more evidence, or new arguments, to cancel out the noise.</p><a id="more"></a><p>The "collapse of the wavefunction" has no experimental
justification, but it appeals to the (undermined) intuition of a single
world.&#xA0; Then it may take an extra argument - say, that collapse violates
Special Relativity - to begin the slow academic disintegration of an
idea that <a href="/lw/q7/if_manyworlds_had_come_first/">should never have been assigned non-negligible probability in the first place</a>.<br>
</p>
<p>From a Bayesian perspective, human academic science as a whole is a
highly inefficient processor of evidence.&#xA0; Each time an unjustifiable
argument shifts belief, you need an extra justifiable argument to shift
it back.&#xA0; The social process of science leans on extra evidence to
overcome cognitive noise.</p>
<p> A more charitable way of putting it is that scientists will adopt positions that are theoretically
<em>insufficiently extreme</em>, compared to the ideal positions that scientists <em>would</em> adopt, if
they were Bayesian AIs and could <a href="/lw/qb/science_doesnt_trust_your_rationality/">trust themselves</a> to reason clearly.</p>
<p>But don't be too charitable.&#xA0; The noise we are talking about is not all innocent mistakes.&#xA0; In many fields, debates drag on for decades after they should have been settled.&#xA0; And <em>not </em>because the scientists on both sides <a href="/lw/qb/science_doesnt_trust_your_rationality/">refuse to trust themselves</a> and agree they should look for additional evidence.&#xA0; But because one side keeps throwing up more and more ridiculous objections, and demanding more and more evidence, from an entrenched position of academic power, long after it becomes clear from which quarter the winds of evidence are blowing.&#xA0; (I'm thinking here about the debates surrounding the invention of <a href="/lw/l1/evolutionary_psychology/">evolutionary psychology</a>, not about many-worlds.)</p>
<p>Is it possible for individual humans or groups to process evidence more efficiently - reach correct conclusions faster - than human academic science as a whole?</p>
<p>"Ideas are tested by experiment.&#xA0; That is the core of science."&#xA0; And this must be true, because if you can't trust <a href="http://xkcd.com/397/">Zombie Feynman</a>, who <em>can </em>you trust?</p>
<p>Yet where do the <em>ideas</em> come from?</p>
<p>You may be tempted to reply, "They come from scientists.&#xA0; Got any other questions?"&#xA0; In Science you're not supposed to care <em>where</em> the hypotheses come from - just whether they pass or fail experimentally.</p>
<p>Okay, but if you remove <em>all</em> new ideas, the scientific process as a
whole stops working because it has no alternative hypotheses to test.&#xA0; 
So inventing new ideas is not a dispensable part of the process.</p>
<p>Now put your Bayesian goggles back on.&#xA0; As described in <a href="/lw/jo/einsteins_arrogance/">Einstein's Arrogance</a>,
there are queries that are not binary - where the answer is not "Yes"
or "No", but drawn from a larger space of structures, e.g., the space
of equations.&#xA0; In such cases it takes far more Bayesian evidence to <em>promote a hypothesis to your attention</em> than to <em>confirm the hypothesis.</em></p>
<p>If you're working in the space of all equations that can be
specified in 32 bits or less, you're working in a space of 4 billion
equations.&#xA0; It takes far more Bayesian evidence to raise one of those
hypotheses to the 10% probability level, than it requires <em>further</em> Bayesian evidence to raise the hypothesis from 10% to 90% probability.
</p>
<p>When the idea-space is large, coming up with ideas worthy of testing, involves much more work - in the <a href="/lw/o5/the_second_law_of_thermodynamics_and_engines_of/">Bayesian-thermodynamic sense of "work"</a> - than <em>merely </em>obtaining an experimental result with p&lt;0.0001 for the new hypothesis over the old hypothesis.<br>
</p>
<p dragover="true">If this doesn't seem obvious-at-a-glance, pause here and read <a href="/lw/jo/einsteins_arrogance/">Einstein's Arrogance</a>.</p>
<p dragover="true">The scientific process has always relied on
scientists to come up with hypotheses to test, via some process not
further specified by Science.&#xA0; Suppose you
came up with some way of generating hypotheses that was completely
crazy - say, pumping a robot-controlled Ouija board with the digits of
pi - and the resulting suggestions kept on getting verified
experimentally.&#xA0; The pure ideal essence of Science wouldn't skip a
beat.&#xA0; The pure ideal essence of Bayes would burst into flames and die.</p>
<p dragover="true">(Compared to Science, Bayes is <a href="/lw/if/your_strength_as_a_rationalist/">falsified by more of the possible outcomes</a>.)</p>
<p>This doesn't mean that the process of deciding which ideas to test is <em>unimportant</em> to Science.&#xA0; It means that Science doesn't <em>specify</em> it.</p>
<p><em>In practice</em>, the robot-controlled Ouija board doesn't work. 
In practice, there are some scientific queries with a large enough
answer space, that picking models at random to test, it would take
zillions of years to hit on a model that made good predictions - like
getting monkeys to type Shakespeare.</p>
<p>At the <em>frontier</em> of science - the boundary between ignorance and knowledge, where science <em>advances</em>
- the process relies on at least some individual scientists (or working
groups) seeing things that are not yet confirmed by Science.&#xA0; That's
how they know which hypotheses to test, in advance of the test itself.</p>
<p>If you take your Bayesian goggles off, you can say, "Well, they don't have to know, they just have to guess."&#xA0; If you put your Bayesian goggles back on, you realize that "guessing" with 10% probability requires nearly as much epistemic work to have been successfully performed, behind the scenes, as "guessing" with 80% probability - at least for large answer spaces.</p>
<p>The scientist may not <em>know</em> he has done this epistemic work successfully, in advance of the experiment; but he must, in fact, have done it successfully!&#xA0; Otherwise he will not even <em>think</em> of the correct hypothesis.&#xA0; In large answer spaces, anyway.</p>
<p>So the scientist makes the novel prediction, performs the experiment, publishes the result, and <em>now </em>Science knows it too.&#xA0; It is now part of the <a href="/lw/in/scientific_evidence_legal_evidence_rational/">publicly accessible knowledge of humankind</a>, that anyone can verify for themselves.</p>
<p>In between was an interval where the scientist rationally knew
something that the public social process of science hadn't yet confirmed.&#xA0; And this is not a trivial
interval, though it may be short; for it is where the <em>frontier</em> of science lies, the advancing border.</p>
<p>All of this is more true for non-routine science than for routine science, because it is a notion of large answer spaces where the answer is not "Yes" or "No" or drawn from a small set of obvious alternatives.&#xA0; It is much easier to train people to test ideas, than to have good ideas to test.</p></div></div></div>