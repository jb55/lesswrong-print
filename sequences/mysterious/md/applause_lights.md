
# Applause Lights

At the Singularity Summit 2007, one of the speakers called for
democratic, multinational development of AI.  So I stepped up to
the microphone and asked:

> Suppose that a group of democratic republics form a consortium to
> develop AI, and there's a lot of politicking during the process -
> some interest groups have unusually large influence, others get
> shafted - in other words, the result looks just like the products
> of modern democracies.  Alternatively, suppose a group of rebel
> nerds develops an AI in their basement, and instructs the AI to
> poll everyone in the world - dropping cellphones to anyone who
> doesn't have them - and do whatever the majority says.  Which of
> these do you think is more "democratic", and would you feel safe
> with either?

I wanted to find out whether he believed in the pragmatic adequacy
of the democratic political process, or if he believed in the moral
rightness of voting.  But the speaker replied:

> The first scenario sounds like an editorial in Reason magazine, and
> the second sounds like a Hollywood movie plot.

Confused, I asked:

> Then what kind of democratic process *did* you have in mind?

The speaker replied:

> Something like the Human Genome Project - that was an
> internationally sponsored research project.

I asked:

> How would different interest groups resolve their conflicts in a
> structure like the Human Genome Project?

And the speaker said:

> I don't know.

This exchange puts me in mind of a
[quote](http://www.time.com/time/magazine/article/0,9171,954853,00.html)
(
which I failed to Google
found by Jeff Grey and Miguel) from some dictator or other, who was
asked if he had any intentions to move his pet state toward
democracy:
> We believe we are already within a democratic system.  Some factors
> are still missing, like the expression of the people's will.

The substance of a democracy is the specific mechanism that
resolves policy conflicts.  If all groups had the same preferred
policies, there would be no need for democracy - we would
automatically cooperate.  The resolution process can be a direct
majority vote, or an elected legislature, or even a voter-sensitive
behavior of an AI, but it has to be *something. *What does it
*mean* to call for a "democratic" solution if you don't have a
conflict-resolution mechanism in mind?

I think it means that you have said the word "democracy", so the
audience is supposed to cheer.  It's not so much a
propositional* *statement, as the equivalent of the "Applause"
light that tells a studio audience when to clap.

This case is remarkable only in that I mistook the applause light
for a policy suggestion, with subsequent embarrassment for all. 
Most applause lights are much more blatant, and can be detected by
a simple reversal test.  For example, suppose someone says:

> We need to balance the risks and opportunities of AI.

If you reverse this statement, you get:

> We shouldn't balance the risks and opportunities of AI.

Since the reversal sounds *ab*normal, the unreversed statement is
probably normal, implying it does not convey new information. 
There are plenty of legitimate reasons for uttering a sentence that
would be uninformative in isolation.  "We need to balance the risks
and opportunities of AI" can introduce a discussion topic; it can
emphasize the importance of a specific proposal for balancing; it
can criticize an unbalanced proposal.  Linking to a normal
assertion can convey new information to a bounded rationalist - the
link itself may not be obvious.  But if *no* specifics follow, the
sentence is probably an applause light.

I am tempted to give a talk sometime that consists of *nothing but*
applause lights, and see how long it takes for the audience to
start laughing:

> I am here to propose to you today that we need to balance the risks
> and opportunities of advanced Artificial Intelligence.  We should
> avoid the risks and, insofar as it is possible, realize the
> opportunities.  We should not needlessly confront entirely
> unnecessary dangers.  To achieve these goals, we must plan wisely
> and rationally.  We should not act in fear and panic, or give in to
> technophobia; but neither should we act in blind enthusiasm.  We
> should respect the interests of all parties with a stake in the
> Singularity.  We must try to ensure that the benefits of advanced
> technologies accrue to as many individuals as possible, rather than
> being restricted to a few.  We must try to avoid, as much as
> possible, violent conflicts using these technologies; and we must
> prevent massive destructive capability from falling into the hands
> of individuals.  We should think through these issues before, not
> after, it is too late to do anything about them...
