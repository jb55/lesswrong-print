
# 31 Laws of Fun

So this is Utopia, is it?  Well  
I beg your pardon, I thought it was Hell.  
        -- Sir Max Beerholm, verse entitled  
       
*In a Copy of More's (or Shaw's or Wells's or Plato's or Anybody's) Utopia*

This is a shorter summary of the
[Fun Theory Sequence](/lw/xy/the_fun_theory_sequence/) with all the
background theory left out - just the compressed advice to the
would-be author or futurist who wishes to imagine a world where
people *might actually want to live:*

1.  Think of a *typical day* in the life of someone who's been
    adapting to Utopia *for a while.*  Don't anchor on the first moment
    of "hearing the good news".  Heaven's "You'll never have to work
    again, and the streets are paved with gold!" sounds like good news
    to a tired and poverty-stricken peasant, but two months later it
    might not be so much fun. 
    ([Prolegomena to a Theory of Fun](/lw/wv/prolegomena_to_a_theory_of_fun/).)
2.  Beware of packing your Utopia with things you think people
    *should* do that aren't actually *fun*.  Again, consider Christian
    Heaven: singing hymns doesn't sound like loads of endless fun, but
    you're *supposed*to enjoy praying, so no one can point this out. 
    ([Prolegomena to a Theory of Fun](/lw/wv/prolegomena_to_a_theory_of_fun/).)
3.  Making a video game easier doesn't always improve it.  The same
    holds true of a life.  Think in terms of clearing out low-quality
    drudgery to make way for high-quality challenge, rather than
    eliminating work.  ([High Challenge](/lw/ww/high_challenge/).)
4.  Life should contain novelty - experiences you haven't
    encountered before, preferably teaching you something you didn't
    already know.  If there isn't a sufficient supply of novelty
    (relative to the speed at which you generalize), you'll get bored. 
    ([Complex Novelty](/lw/wx/complex_novelty/).)

5.  People should get smarter at a rate sufficient to integrate
    their old experiences, but not so much smarter so fast that they
    can't integrate their new intelligence.  Being smarter means you
    get bored faster, but you can also tackle new challenges you
    couldn't understand before. 
    ([Complex Novelty](/lw/wx/complex_novelty/).)
6.  People should live in a world that fully engages their senses,
    their bodies, and their brains.  This means either that the world
    resembles the ancestral savanna more than say a windowless office;
    or alternatively, that brains and bodies have changed to be fully
    engaged by different kinds of complicated challenges and
    environments.  (Fictions intended to entertain a human audience
    should concentrate primarily on the former option.) 
    ([Sensual Experience](/lw/wy/sensual_experience/).)
7.  Timothy Ferris:  "What is the opposite of happiness?  Sadness? 
    No.  Just as love and hate are two sides of the same coin, so are
    happiness and sadness...  The opposite of love is indifference, and
    the opposite of happiness is - here's the clincher - boredom... 
    The question you should be asking isn't 'What do I want?' or 'What
    are my goals?' but 'What would excite me?'...  *Living* like a
    millionaire requires *doing* interesting things and not just owning
    enviable things." 
    ([Existential Angst Factory](/lw/sc/existential_angst_factory/).)
8.  Any particular individual's life should get better and better
    over time. 
    ([Continuous Improvement](/lw/xk/continuous_improvement/).)
9.  You should not know exactly what improvements the future holds,
    although you should look forward to finding out.  The actual event
    should come as a pleasant surprise. 
    ([Justified Expectation of Pleasant Surprises](/lw/xo/justified_expectation_of_pleasant_surprises/).)
10. Our hunter-gatherer ancestors strung their own bows, wove their
    own baskets and whittled their own flutes; then they did their own
    hunting, their own gathering and played their own music. 
    Futuristic Utopias are often depicted as offering more and more
    neat buttons that do less and less comprehensible things *for*you. 
    Ask not what interesting things Utopia can do *for*people; ask
    rather what interesting things the inhabitants could do for
    *themselves*- with their own brains, their own bodies, or tools
    they understand how to build. 
    ([Living By Your Own Strength](/lw/wz/living_by_your_own_strength/).)
11. Living in Eutopia should make people stronger, not weaker, over
    time.  The inhabitants should appear *more formidable* than the
    people of our own world, not less. 
    ([Living By Your Own Strength](/lw/wz/living_by_your_own_strength/);
    see also,
    [Tsuyoku Naritai](/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/).)
12. Life should not be broken up into a series of disconnected
    episodes with no long-term consequences.  No matter how sensual or
    complex, playing one *really great video game* after another, does
    not make a life story. 
    ([Emotional Involvement](/lw/xg/emotional_involvement/).)
13. People should make their own destinies; their lives should not
    be choreographed to the point that they no longer need to imagine,
    plan and navigate their own futures.  Citizens should not be the
    pawns of more powerful gods, still less their sculpted material. 
    One simple solution would be to have the world work by stable rules
    that are the same for everyone, where the burden of Eutopia is
    carried by a good initial choice of rules, rather than by any
    optimization pressure applied to individual lives. 
    ([Free to Optimize](/lw/xb/free_to_optimize/).)
14. Human minds should not have to *play on a level field* with
    vastly superior entities.  Most people don't like being
    overshadowed.  Gods destroy a human protagonist's "main character"
    status; this is undesirable in fiction and probably in real life. 
    (E.g.:  C. S. Lewis's Narnia, Iain Banks's Culture.)  Either change
    people's emotional makeup so that they don't *mind*being
    unnecessary, or keep the gods *way*off their playing field. 
    Fictional stories intended for human audiences cannot do the
    former.  (And in real life, you probably *can* have powerful AIs
    that are neither sentient nor meddlesome.  See the main post and
    its prerequisites.) 
    ([Amputation of Destiny](/lw/x8/amputation_of_destiny/).)
15. Trying to compete on a single flat playing field with
    *six billion other humans*also creates problems.  Our ancestors
    lived in bands of around 50 people.  Today the media is constantly
    bombarding us with news of *exceptionally*rich and pretty people as
    if they lived next door to us; and very few people get a chance to
    be the *best*at any specialty. 
    ([Dunbar's Function](/lw/x9/dunbars_function/).)
16. Our ancestors also had some degree of genuine control over
    their band's politics.  Contrast to modern nation-states where
    almost no one knows the President on a personal level or could
    argue Congress out of a bad decision.  (Though that doesn't stop
    people from arguing as loudly as if they still lived in a 50-person
    band.)  ([Dunbar's Function](/lw/x9/dunbars_function/).)
17. Offering people more options is *not*always helping them
    (especially if the option is something they couldn't do for
    themselves).  Losses are more painful than the corresponding gains,
    so if choices are different along many dimensions and only one
    choice can be taken, people tend to focus on the loss of the road
    *not*taken.  Offering a road that bypasses a challenge makes the
    challenge feel less real, even if the cheat is diligently refused. 
    It is also a sad fact that humans predictably make certain kinds of
    mistakes.  Don't assume that building *more choice* into your
    Utopia is necessarily an improvement because "people can always
    just say no".  This *sounds reassuring* to an outside reader -
    "Don't worry, *you'll* decide!  You trust *yourself*, right?" - but
    might not be much fun to actually *live*with. 
    ([Harmful Options](/lw/x2/harmful_options/).)
18. Extreme example of the above: being constantly offered huge
    temptations that are incredibly dangerous - a completely realistic
    virtual world, or very addictive and pleasurable drugs.  You can
    never allow yourself a single moment of willpower failure over your
    whole life.  (E.g.:  John C. Wright's Golden Oecumene.) 
    ([Devil's Offers](/lw/x3/devils_offers/).)
19. Conversely, when people are grown strong enough to shoot off
    their feet *without external help,* stopping them may be too much
    interference.  Hopefully they'll then be smart enough *not* to:  By
    the time they can build the gun, they'll know what happens if they
    pull the gun, and won't need a smothering safety blanket.  If
    that's the theory, then dangerous options need correspondingly
    difficult locks.  ([Devil's Offers](/lw/x3/devils_offers/).)
20. *Telling* people truths they haven't yet figured out for
    themselves, is not always helping them. 
    ([Joy in Discovery](/lw/os/joy_in_discovery/).)
21. Brains are some of the most complicated things in the world. 
    Thus, other humans (other minds) are some of the most complicated
    things we deal with.  For us, this interaction has a unique
    character because of the *sympathy*we feel for others - the way
    that our brain tends to align with their brain - rather than our
    brain just treating other brains as big complicated machines with
    levers to pull.  Reducing the need for people to interact with
    other people reduces the complexity of human existence; this is a
    step in the wrong direction.  For example, resist the temptation to
    *simplify people's lives* by offering them artificially perfect
    sexual/romantic partners.
    ([Interpersonal Entanglement](/lw/xt/interpersonal_entanglement/).)
22. But admittedly, humanity does have a *statistical*sex problem:
    the male distribution of attributes doesn't harmonize with the
    female distribution of desires, or vice versa.  Not everything in
    Eutopia should be easy - but it shouldn't be pointlessly,
    unresolvably frustrating either.  (This is a general principle.) 
    So imagine *nudging* the distributions to make the problem
    *solvable* - rather than waving a magic wand and solving everything
    instantly. 
    ([Interpersonal Entanglement](/lw/xt/interpersonal_entanglement/).)
23. In general, tampering with brains, minds, emotions, and
    personalities is way more fraught on every possible level of ethics
    and difficulty, than tampering with bodies and environments. 
    Always ask what you can do by messing with the environment before
    you imagine messing with minds.  Then prefer small cognitive
    changes to big ones.  You're not just outrunning your human
    audience, you're outrunning your own imagination. 
    ([Changing Emotions](/lw/xe/changing_emotions/).)
24. In this present world, there is an imbalance between pleasure
    and pain.  An unskilled torturer with simple tools can create worse
    pain in thirty seconds, than an extremely skilled sexual artist can
    create pleasure in thirty minutes.  One response would be to
    *remedy the imbalance* - to have the world contain *more*joy than
    sorrow.  Pain might exist, but not pointless endless unendurable
    pain.  Mistakes would have more *proportionate*penalties:  You
    might touch a hot stove and end up with a painful blister; but not
    glance away for two seconds and spend the rest of your life in a
    wheelchair.  The people would be stronger, less exhausted.  This
    path would eliminate *mind-destroying* pain, and make pleasure more
    abundant.  Another path would eliminate pain *entirely*.  Whatever
    the relative merits of the real-world proposals,
    *fictional stories cannot take the second path.* 
    ([Serious Stories](/lw/xi/serious_stories/).)
25. George Orwell once observed that Utopias are chiefly concerned
    with avoiding fuss.  Don't be afraid to write a loud Eutopia that
    might wake up the neighbors. 
    ([Eutopia is Scary](/lw/xl/eutopia_is_scary/); George Orwell's
    [Why Socialists Don't Believe in Fun](http://www.orwell.ru/library/articles/socialists/english/e_fun).)
26. George Orwell observed that "The inhabitants of perfect
    universes seem to have no spontaneous gaiety and are usually
    somewhat repulsive into the bargain."  If you write a story and
    your characters turn out like this, it probably reflects some much
    deeper flaw that can't be fixed by having the State hire a few
    clowns.  (George Orwell's
    [Why Socialists Don't Believe in Fun](http://www.orwell.ru/library/articles/socialists/english/e_fun).)
27. Ben Franklin, yanked into our own era, would be surprised and
    delighted by some aspects of his Future.  Other aspects would
    horrify, disgust, and *frighten* him; and this is not because our
    world has gone *wrong*, but because it has *improved*relative to
    his time.  Relatively few things would have gone *just*as Ben
    Franklin expected.  If you imagine a world which your imagination
    finds familiar and comforting, it will inspire few others, and the
    whole exercise will lack integrity.  Try to conceive of a genuinely
    better world in which you, yourself, would be *shocked*(at least at
    first) and *out of place* (at least at first). 
    ([Eutopia is Scary](/lw/xl/eutopia_is_scary/).)
28. Utopia and Dystopia are two sides of the same coin; both just
    confirm the moral sensibilities you started with.  Whether the
    world is a libertarian utopia of government non-interference, or a
    hellish dystopia of government intrusion and regulation, you get to
    say "I was right all along."  Don't just imagine something that
    conforms to your *existing*ideals of government, relationships,
    politics, work, or daily life.  Find the better world that zogs
    instead of zigging or zagging.  (To safeguard your sensibilities,
    you can tell yourself it's just an *arguably* better world but
    isn't *really* better than your favorite standard Utopia... but
    you'll know you're *really*doing it right if you find your ideals
    *changing*.)  ([Building Weirdtopia](/lw/xm/building_weirdtopia/).)
29. If your Utopia still seems like an endless gloomy drudgery of
    existential angst no matter how much you try to brighten it,
    there's at least one major problem that you're
    *entirely failing to focus on*. 
    ([Existential Angst Factory](/lw/sc/existential_angst_factory/).)
30. 'Tis a sad mind that cares about nothing except itself.  In the
    modern-day world, if an altruist looks around, their eye is caught
    by large groups of people in desperate jeopardy.  People in a
    better world will *not*see this:  A true Eutopia will run low on
    victims to be rescued.  This doesn't imply that the inhabitants
    look around outside themselves and see *nothing*.  They may care
    about friends and family, truth and freedom, common projects;
    outside minds, shared goals, and high ideals. 
    ([Higher Purpose](/lw/xw/higher_purpose/).)
31. Still, a story that confronts the challenge of Eutopia should
    *not*just have the convenient plot of "The Dark Lord Sauron is
    about to invade and kill everybody".  The would-be author will have
    to find something *slightly less awful*for his characters to
    *legitimately care about*.  This is part of the challenge of
    showing that human progress is not the end of human stories, and
    that people *not* in imminent danger of death can still lead
    interesting lives.  Those of you interested in confronting lethal
    planetary-sized dangers should focus on *present-day real life*. 
    ([Higher Purpose](/lw/xw/higher_purpose/).)

The simultaneous solution of all these design requirements is left
as an exercise to the reader.  At least for now.

The enumeration in this post of certain Laws shall not be construed
to deny or disparage others not mentioned.  I didn't happen to
write about humor, but it would be a sad world that held no
laughter, etcetera.

To anyone seriously interested in trying to write a Eutopian story
using these Laws:  You must first know *how to write*.  There are
many, many books on how to write; you should read at least three;
and they will all tell you that a great deal of practice is
required.  Your practice stories should *not*be composed anywhere
so difficult as Eutopia.  That said, my *second*most important
advice for authors is this:  Life will never become boringly easy
for your characters so long as they can make things difficult for
each other.

Finally, this dire warning: 
[Concretely imagining worlds much better than your present-day real life, may suck out your soul like an emotional vacuum cleaner](/lw/xp/seduced_by_imagination/). 
(See [Seduced by Imagination](/lw/xp/seduced_by_imagination/).) 
Fun Theory is dangerous, use it with caution, you have been
warned.
